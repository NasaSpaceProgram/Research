{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM1ilYbtMApEBHVhNJIZ3jR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NasaSpaceProgram/Research/blob/main/MISSFIT_Parsing_CRIS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ba2vQZIxh3eP"
      },
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3u8mKXPfSuEZ"
      },
      "source": [
        "def ParseHeader1(line,ouptf):\n",
        "    ln = line.split()\n",
        "    ouptf.write(','.join(ln) + \"\\n\")\n",
        "def ParseHeader(line,ouptf):\n",
        "    ouptf.write(line)\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "def ParseLine(line,ouptf):\n",
        "    \n",
        "    # Split the line into its columns\n",
        "    # note: the split here is assuming that we can split with spaces if not you will need to use somthing like line.split(\",\")\n",
        "    ln = line.split()\n",
        "    ouptf.write(','.join(ln) + \"\\n\")\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "def ParseToFile(filename, ouptFileName, header = 0):\n",
        "    \"\"\"Parses a data file into a list of dictionaries\n",
        "        file name -- string\n",
        "        header -- int -- number of lines of the header\n",
        "        Note this assumes that all header lines are parced the same way and all data lines are parced the same way\"\"\"\n",
        "    # call the file into \"wrapper\" variable f\n",
        "    f = open (filename,\"r\")\n",
        "    ouptf = open(ouptFileName, \"w\") #for if we need to open a file and erase its contence\n",
        "    #ouptf = open(ouptFileName, \"a\") #for if we need to open a file without erasing its contence\n",
        "\n",
        "    \n",
        "\n",
        "    #Parse the header\n",
        "    for ln in range(header-2):\n",
        "        line = f.readline()\n",
        "        ParseHeader(line,ouptf)\n",
        "\n",
        "    line = f.readline()\n",
        "    ParseHeader1(line, ouptf)\n",
        "\n",
        "    line = f.readline()\n",
        "    ParseHeader(line,ouptf)\n",
        "\n",
        "    # Parse the data\n",
        "    for line in f:\n",
        "        ParseLine(line, ouptf)\n",
        "        \n",
        "    # close our file so it is not taking up memory\n",
        "    f.close()\n",
        "\n",
        "\n",
        "def ParseToFile_WH(filename, ouptFileName, header = 0):\n",
        "    \"\"\"Parses a data file into a list of dictionaries\n",
        "        file name -- string\n",
        "        header -- int -- number of lines of the header\n",
        "        Note this assumes that all header lines are parced the same way and all data lines are parced the same way\"\"\"\n",
        "    # call the file into \"wrapper\" variable f\n",
        "    f = open (filename,\"r\")\n",
        "    #ouptf = open(ouptFileName, \"w\") #for if we need to open a file and erase its contence\n",
        "    ouptf = open(ouptFileName, \"a\") #for if we need to open a file without erasing its contence\n",
        "\n",
        "    #Parse the header\n",
        "    for ln in range(header):\n",
        "        line = f.readline()\n",
        "\n",
        "    # Parse the data\n",
        "    for line in f:\n",
        "        ParseLine(line, ouptf)\n",
        "        \n",
        "    # close our file so it is not taking up memory\n",
        "    f.close()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9UALsQAXk-h",
        "outputId": "158e41de-835d-4f65-cf23-a50bef5ee0e4"
      },
      "source": [
        "drive.mount('/content/drive') #/MyDrive/Research/datasets\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xC6tXkddX204"
      },
      "source": [
        " ParseToFile('/content/drive/MyDrive/Missfit/MISSFIT_Collaboration/Radiation_Group/GCR_Composition_Energy/ACE_CRIS_Data/ASCYpF3Js', '/content/drive/MyDrive/Missfit/MISSFIT_Collaboration/Radiation_Group/GCR_Composition_Energy/ACE_CRIS_Data/ACE_CRIS_Data_Parced.csv',22)\n"
      ],
      "execution_count": 6,
      "outputs": []
    }
  ]
}