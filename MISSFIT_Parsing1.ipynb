{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNXMS8XzL/uCVHWN73ZFkYo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NasaSpaceProgram/Research/blob/main/MISSFIT_Parsing1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ba2vQZIxh3eP"
      },
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3u8mKXPfSuEZ"
      },
      "source": [
        "def ParseHeader1(line,ouptf):\n",
        "    ln = line.split()\n",
        "    oupt.insert(0,\"Total Years\")\n",
        "\n",
        "def ParseHeader(line,ouptf):\n",
        "    ouptf.write(line)\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "def ParseLine(line,ouptf):\n",
        "    \n",
        "    # Split the line into its columns\n",
        "    # note: the split here is assuming that we can split with spaces if not you will need to use somthing like line.split(\",\")\n",
        "    ln = line.split()\n",
        "    # Careful with how this is being split\n",
        "\n",
        "    #split down the time catagory further and use it to get the years\n",
        "    #year month day doy hour minute\n",
        "    #years = float(times[0]) + ((float(times[1]) + (float(times[4]) + (float(times[5])/60))/24)/365.25)\n",
        "    years = float(ln[0]) + (float(ln[1])/365.25) + (float(ln[4])/(360.25*24)) + (float(ln[5])/(360.25*24*60))\n",
        "    ln.insert(0,str(years))\n",
        "    ouptf.write(','.join(ln) + \"\\n\")\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "def ParseToFile(filename, ouptFileName, header = 0):\n",
        "    \"\"\"Parses a data file into a list of dictionaries\n",
        "        file name -- string\n",
        "        header -- int -- number of lines of the header\n",
        "        Note this assumes that all header lines are parced the same way and all data lines are parced the same way\"\"\"\n",
        "    # call the file into \"wrapper\" variable f\n",
        "    f = open (filename,\"r\")\n",
        "    #ouptf = open(ouptFileName, \"w\") #for if we need to open a file and erase its contence\n",
        "    ouptf = open(ouptFileName, \"a\") #for if we need to open a file without erasing its contence\n",
        "\n",
        "    line = f.readline()\n",
        "    ParseHeader1(line, ouptf)\n",
        "\n",
        "    #Parse the header\n",
        "    for ln in range(header-1):\n",
        "        line = f.readline()\n",
        "        ParseHeader(line,ouptf)\n",
        "\n",
        "    # Parse the data\n",
        "    for line in f:\n",
        "        ParseLine(line, ouptf)\n",
        "        \n",
        "    # close our file so it is not taking up memory\n",
        "    f.close()\n",
        "\n",
        "\n",
        "def ParseToFile_WH(filename, ouptFileName, header = 0):\n",
        "    \"\"\"Parses a data file into a list of dictionaries\n",
        "        file name -- string\n",
        "        header -- int -- number of lines of the header\n",
        "        Note this assumes that all header lines are parced the same way and all data lines are parced the same way\"\"\"\n",
        "    # call the file into \"wrapper\" variable f\n",
        "    f = open (filename,\"r\")\n",
        "    #ouptf = open(ouptFileName, \"w\") #for if we need to open a file and erase its contence\n",
        "    ouptf = open(ouptFileName, \"a\") #for if we need to open a file without erasing its contence\n",
        "\n",
        "    #Parse the header\n",
        "    for ln in range(header):\n",
        "        line = f.readline()\n",
        "\n",
        "    # Parse the data\n",
        "    for line in f:\n",
        "        ParseLine(line, ouptf)\n",
        "        \n",
        "    # close our file so it is not taking up memory\n",
        "    f.close()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bMJ07M6XS7i"
      },
      "source": [
        "def Mn():\n",
        "    ParseToFile('/content/drive/MyDrive/Missfit/MISSFIT_Collaboration/Test.txt', '/content/drive/MyDrive/Missfit/MISSFIT_Collaboration/Test1, 0')\n",
        "\n",
        "\n",
        "#'/content/drive/MyDrive/Missfit/MISSFIT_Collaboration/Radiation_Group/Solar_Wind_Composition_and_Energy/Nasa_Data/SOHO/10min/1995.l3i'\n",
        "def Main(inptfs, ouptf, header = 0):\n",
        "    \"\"\"Takes in a list of input files and parses the data into an input file\"\"\"\n",
        "    ParseToFile(inptfs[0], ouptf, header)\n",
        "    for i in range(len(inptfs)-1):\n",
        "        ParseToFile_WH(inptfs[i+1], ouptf, header)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "k9UALsQAXk-h",
        "outputId": "ee50b653-0eb7-4be1-c715-ff63dbbece77"
      },
      "source": [
        "drive.mount('/content/drive') #/MyDrive/Research/datasets\n",
        "Mn();\n",
        "\n",
        "\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-01e4934ebf5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#/MyDrive/Research/datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mMn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-64b91fa68ffd>\u001b[0m in \u001b[0;36mMn\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mMn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mParseToFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Missfit/MISSFIT_Collaboration/Test.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/drive/MyDrive/Missfit/MISSFIT_Collaboration/Test1, 0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#'/content/drive/MyDrive/Missfit/MISSFIT_Collaboration/Radiation_Group/Solar_Wind_Composition_and_Energy/Nasa_Data/SOHO/10min/1995.l3i'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-6874d349f9ac>\u001b[0m in \u001b[0;36mParseToFile\u001b[0;34m(filename, ouptFileName, header)\u001b[0m\n\u001b[1;32m     32\u001b[0m         Note this assumes that all header lines are parced the same way and all data lines are parced the same way\"\"\"\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# call the file into \"wrapper\" variable f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0;31m#ouptf = open(ouptFileName, \"w\") #for if we need to open a file and erase its contence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mouptf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouptFileName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"a\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#for if we need to open a file without erasing its contence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Missfit/MISSFIT_Collaboration/Test.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xC6tXkddX204"
      },
      "source": [
        "Main(,\"ouptFile.csv\",1)\n",
        "Lines = ParseLinesToDictinary('/content/drive/MyDrive/Research/datasets/n4151s1.txt');"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}