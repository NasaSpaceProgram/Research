{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyORU8Qaxgi03rSNoSwiTwOW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NasaSpaceProgram/Research/blob/main/MISSFIT_Parsing_H_5min_30sec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ba2vQZIxh3eP"
      },
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3u8mKXPfSuEZ"
      },
      "source": [
        "def ParseHeader_units(line,ouptf):\n",
        "    s = \"Year,Year,Month,Day,Day,hr,min,sec\"\n",
        "    ln = line.split()\n",
        "    ln[0] = s\n",
        "    ouptf.write(','.join(ln) + \"\\n\")\n",
        "\n",
        "def ParseHeader_col(line,ouptf):\n",
        "    ln = line.split()\n",
        "    lin = ln[3].split(':')\n",
        "    ln.pop(3)\n",
        "\n",
        "    i = -1\n",
        "    for j in range(len(lin)):\n",
        "      ln.insert(3,lin[i-j]) \n",
        "    ln.insert(0,\"Total Years\")\n",
        "    ouptf.write(','.join(ln) + \"\\n\")\n",
        "\n",
        "\n",
        "\n",
        "def ParseHeader(line,ouptf):\n",
        "    ouptf.write(line)\n",
        "\n",
        "\n",
        "\n",
        "def ParseLine(line,ouptf):\n",
        "    ln = line.split()\n",
        "    lin = ln[3].split(':')\n",
        "    ln.pop(3)\n",
        "\n",
        "    i = -1\n",
        "    for j in range(len(lin)):\n",
        "      ln.insert(3,lin[i-j]) \n",
        "\n",
        "    if ln[0][0] == \"9\":\n",
        "      year = 1900 + int(ln[0])\n",
        "    else: \n",
        "      year = 2000 + int(ln[0])\n",
        "    ln[0] = str(year)\n",
        "\n",
        "    years = year + (float(lin[0])/365.25) + (float(lin[1])/(360.25*24)) + (float(lin[2])/(360.25*24*60)) + (float(lin[3])/(360.25*24*60*60))\n",
        "    ln.insert(0,str(years))\n",
        "    ouptf.write(','.join(ln) + \"\\n\")\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "def ParseToFile(filename, ouptFileName, header = 0):\n",
        "    \"\"\"Parses a data file into a list of dictionaries\n",
        "        file name -- string\n",
        "        header -- int -- number of lines of the header\n",
        "        Note this assumes that all header lines are parced the same way and all data lines are parced the same way\"\"\"\n",
        "    # call the file into \"wrapper\" variable f\n",
        "    f = open (filename,\"r\")\n",
        "    #ouptf = open(ouptFileName, \"w\") #for if we need to open a file and erase its contence\n",
        "    ouptf = open(ouptFileName, \"a\") #for if we need to open a file without erasing its contence\n",
        "\n",
        "    \n",
        "\n",
        "    #Parse the header\n",
        "    for ln in range(header-2):\n",
        "        line = f.readline()\n",
        "        ParseHeader(line,ouptf)\n",
        "\n",
        "    line = f.readline()\n",
        "    ParseHeader_units(line, ouptf)\n",
        "\n",
        "    line = f.readline()\n",
        "    ParseHeader_col(line, ouptf)\n",
        "\n",
        "    # Parse the data\n",
        "    for line in f:\n",
        "        ParseLine(line, ouptf)\n",
        "        \n",
        "    # close our file so it is not taking up memory\n",
        "    f.close()\n",
        "\n",
        "\n",
        "def ParseToFile_WH(filename, ouptFileName, header = 0):\n",
        "    \"\"\"Parses a data file into a list of dictionaries\n",
        "        file name -- string\n",
        "        header -- int -- number of lines of the header\n",
        "        Note this assumes that all header lines are parced the same way and all data lines are parced the same way\"\"\"\n",
        "    # call the file into \"wrapper\" variable f\n",
        "    f = open (filename,\"r\")\n",
        "    #ouptf = open(ouptFileName, \"w\") #for if we need to open a file and erase its contence\n",
        "    ouptf = open(ouptFileName, \"a\") #for if we need to open a file without erasing its contence\n",
        "\n",
        "    #Parse the header\n",
        "    for ln in range(header+1):\n",
        "        line = f.readline()\n",
        "\n",
        "    # Parse the data\n",
        "    for line in f:\n",
        "        ParseLine(line, ouptf)\n",
        "        \n",
        "    # close our file so it is not taking up memory\n",
        "    f.close()"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bMJ07M6XS7i"
      },
      "source": [
        "\n",
        "#'/content/drive/MyDrive/Missfit/MISSFIT_Collaboration/Radiation_Group/Solar_Wind_Composition_and_Energy/NASA_Data/SOHO/10min/1995.l3i'\n",
        "def Main(inptfs, ouptf, header = 0):\n",
        "    \"\"\"Takes in a list of input files and parses the data into an input file\"\"\"\n",
        "    ParseToFile(inptfs[0], ouptf, header)\n",
        "    for i in range(len(inptfs)-1):\n",
        "        ParseToFile_WH(inptfs[i+1], ouptf, header)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9UALsQAXk-h",
        "outputId": "eff78868-ca2a-4b1d-c8d4-499d13684686"
      },
      "source": [
        "drive.mount('/content/drive') #/MyDrive/Research/datasets\n",
        "\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yR3ebuNiGQSP"
      },
      "source": [
        "def Mn():\n",
        "    ParseToFile('/content/drive/MyDrive/Missfit/MISSFIT_Collaboration/Radiation_Group/Solar_Wind_Composition_and_Energy/NASA_Data/SOHO/H_data/Proton_Monitor_5min/1996_CELIAS_Proton_Monitor.txt', '/content/drive/MyDrive/Missfit/MISSFIT_Collaboration/Radiation_Group/Solar_Wind_Composition_and_Energy/NASA_Data/SOHO/H_data/Proton_Monitor_5min/test.csv',28)\n",
        "\n",
        "Mn();"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xC6tXkddX204"
      },
      "source": [
        "\n",
        "tme = \"30sec\"\n",
        "lst = []\n",
        "for i in range(1996,2019):\n",
        "  lst.append(\"/content/drive/MyDrive/Missfit/MISSFIT_Collaboration/Radiation_Group/Solar_Wind_Composition_and_Energy/NASA_Data/SOHO/H_data/Proton_Monitor_\"+ tme+ \"/\" + str(i) + \".txt\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Main(lst,\"/content/drive/MyDrive/Missfit/MISSFIT_Collaboration/Radiation_Group/Solar_Wind_Composition_and_Energy/NASA_Data/SOHO/H_data/Proton_Monitor_Parced_\"+ tme +\"_Data.csv\",28)\n"
      ],
      "execution_count": 62,
      "outputs": []
    }
  ]
}